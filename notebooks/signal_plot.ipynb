{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn import input_data\n",
    "from nilearn import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/hyruuk/GitHub/neuromod/shinobi_fmri/data/processed/cmaps/run-level/Hit/sub-01_ses-002_run-01.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "img = nib.load(filepath)\n",
    "arrdata = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shinobi_behav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a5e965f86e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mload_confounds\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshinobi_fmri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrim_events_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_scrub_regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/shinobi_fmri-0.1.0-py3.7.egg/shinobi_fmri/annotations/annotations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mshinobi_behav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_framewise_aps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shinobi_behav'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nilearn import image, signal\n",
    "from load_confounds import Confounds\n",
    "from shinobi_fmri.annotations.annotations import trim_events_df, get_scrub_regressor\n",
    "import numpy as np\n",
    "import pdb\n",
    "import argparse\n",
    "import nilearn\n",
    "import shinobi_behav\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn import plotting\n",
    "\n",
    "figures_path = shinobi_behav.figures_path#'/home/hyruuk/GitHub/neuromod/shinobi_fmri/reports/figures/'\n",
    "path_to_data = shinobi_behav.path_to_data#'/media/storage/neuromod/shinobi_data/'\n",
    "sub = 'sub-01'\n",
    "contrast = 'Hit'\n",
    "ses = 'ses-002'\n",
    "run = '1'\n",
    "\n",
    "print('Run : {}'.format(run))\n",
    "data_fname = path_to_data + 'shinobi/derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/{}_{}_task-shinobi_run-{}_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'.format(sub, ses, sub, ses, run)\n",
    "confounds_fname = path_to_data + 'shinobi/derivatives/fmriprep-20.2lts/fmriprep/{}/{}/func/{}_{}_task-shinobi_run-{}_desc-confounds_timeseries.tsv'.format(sub, ses, sub, ses, run)\n",
    "anat_fname = path_to_data + 'anat/derivatives/fmriprep-20.2lts/fmriprep/{}/anat/{}_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'.format(sub, sub)\n",
    "cmap_fname = path_to_data + 'processed/cmaps/run-level-allregs/{}/{}_{}_run-0{}.nii.gz'.format(contrast, sub, ses, run)\n",
    "events_fname = path_to_data + 'processed/annotations/{}_{}_run-0{}.csv'.format(sub, ses, run)\n",
    "\n",
    "run_events = pd.read_csv(events_fname)\n",
    "\n",
    "fmri_img = image.concat_imgs(data_fname)\n",
    "bold_shape = fmri_img.shape\n",
    "confounds = Confounds(strategy=['high_pass', 'motion', 'global', 'wm_csf'],\n",
    "                            motion=\"full\", wm_csf='basic',\n",
    "                            global_signal='full').load(data_fname)\n",
    "\n",
    "\n",
    "hrf_model = 'spm'\n",
    "trimmed_df = trim_events_df(run_events, trim_by='event')\n",
    "\n",
    "# create design matrix\n",
    "n_slices = bold_shape[-1]\n",
    "t_r = 1.49\n",
    "frame_times = np.arange(n_slices) * t_r\n",
    "design_matrix = make_first_level_design_matrix(frame_times,\n",
    "                                        events=trimmed_df,\n",
    "                                        drift_model=None,\n",
    "                                        hrf_model=hrf_model,\n",
    "                                        add_regs=confounds,\n",
    "                                        add_reg_names=None)\n",
    "design_matrix = get_scrub_regressor(run_events, design_matrix)\n",
    "fmri_glm = FirstLevelModel(t_r=1.49,\n",
    "                       noise_model='ar1',\n",
    "                       standardize=False,\n",
    "                       hrf_model=hrf_model,\n",
    "                       drift_model=None,\n",
    "                       high_pass=None,\n",
    "                       n_jobs=16,\n",
    "                       smoothing_fwhm=5,\n",
    "                       mask_img=anat_fname,\n",
    "                       minimize_memory=False)\n",
    "\n",
    "fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrix)\n",
    "z_map = fmri_glm.compute_contrast(contrast,\n",
    "                          stat_type='F',\n",
    "                          output_type='z_score')\n",
    "\n",
    "# Extract activation clusters\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn import input_data\n",
    "\n",
    "table = get_clusters_table(z_map, stat_threshold=3.1,\n",
    "                           cluster_threshold=20).set_index('Cluster ID', drop=True)\n",
    "\n",
    "# get the 3 largest clusters' max x, y, and z coordinates\n",
    "coords = table.loc[range(1, 4), ['X', 'Y', 'Z']].values\n",
    "\n",
    "# extract time series from each coordinate\n",
    "masker = input_data.NiftiSpheresMasker(coords)\n",
    "real_timeseries = masker.fit_transform(fmri_img)\n",
    "predicted_timeseries = masker.fit_transform(fmri_glm.predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hyruuk/GitHub/neuromod/shinobi_fmri/notebooks'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shinobi_behav# Importe les librairies\n",
    "from nilearn.datasets import fetch_spm_auditory\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "import pandas as pd\n",
    "\n",
    "# initialisation de la figure\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "# Extract activation clusters\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn import input_data\n",
    "\n",
    "table = get_clusters_table(z_map, stat_threshold=3.1,\n",
    "                           cluster_threshold=20).set_index('Cluster ID', drop=True)\n",
    "\n",
    "# get the 3 largest clusters' max x, y, and z coordinates\n",
    "coords = table.loc[range(1, 4), ['X', 'Y', 'Z']].values\n",
    "\n",
    "# extract time series from each coordinate\n",
    "masker = input_data.NiftiSpheresMasker(coords)\n",
    "real_timeseries = masker.fit_transform(fmri_img)\n",
    "predicted_timeseries = masker.fit_transform(fmri_glm.predicted[0])\n",
    "\n",
    "# Plot figure\n",
    "# colors for each of the clusters\n",
    "colors = ['blue', 'navy', 'purple', 'magenta', 'olive', 'teal']\n",
    "# plot the time series and corresponding locations\n",
    "from nilearn import plotting\n",
    "fig1, axs1 = plt.subplots(2, 3)\n",
    "for i in range(0, 3):\n",
    "    # plotting time series\n",
    "    axs1[0, i].set_title('Cluster peak {}\\n'.format(coords[i]))\n",
    "    axs1[0, i].plot(real_timeseries[:, i], c=colors[i], lw=2)\n",
    "    axs1[0, i].plot(predicted_timeseries[:, i], c='r', ls='--', lw=2)\n",
    "    axs1[0, i].set_xlabel('Time')\n",
    "    axs1[0, i].set_ylabel('Signal intensity', labelpad=0)\n",
    "    # plotting image below the time series\n",
    "    roi_img = plotting.plot_stat_map(\n",
    "        z_map, cut_coords=[coords[i][2]], threshold=3.1, figure=fig1,\n",
    "        axes=axs1[1, i], display_mode='z', colorbar=False, bg_img=mean_img)\n",
    "    roi_img.add_markers([coords[i]], colors[i], 300)\n",
    "\n",
    "fig1.set_size_inches(24, 14)\n",
    "signals_plot_name = figures_path + 'run-level-allregs/{}/signals_{}_{}_run-0{}.png'.format(contrast, sub, ses, run)\n",
    "fig1.savefig(signals_plot_name)\n",
    "# Glue the figure\n",
    "#from myst_nb import glue\n",
    "#glue(\"auditory-fig\", fig1, display=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shinobi_env",
   "language": "python",
   "name": "shinobi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
